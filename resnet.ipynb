{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 레이어 구현"
      ],
      "metadata": {
        "id": "qQjEmhTEbLbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxfrMhX41OxI",
        "outputId": "3da452ea-3037-470c-a0d5-c72d3c98b521"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "73_MLS-IRlHB"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EsBKYmG1WKv",
        "outputId": "83b66c53-d0af-43d0-b003-54f77423e96c"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQjbGVZ-1VOH",
        "outputId": "aa187be6-76e9-4326-c9a1-5fe71e9a46ba"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Basicblock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, stride=1,downsample = None):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        )\n",
        "        self.downsample = downsample\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(identity)\n",
        "        x += identity\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Um3w0kDeSR6x"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        )\n",
        "        self.downsample = downsample\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(identity)\n",
        "        x += identity\n",
        "        x = self.relu1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Dsn-5lmieGAJ"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "      super().__init__()\n",
        "      self.in_channels = 64\n",
        "\n",
        "      self.conv1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7,stride=2, padding=3, bias=False),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "      self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "      self.conv2 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "      self.conv3 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "      self.conv4 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "      self.conv5 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "\n",
        "      self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "      self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(out_channels * block.expansion, out_channels))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = self.pool1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.conv3(x)\n",
        "      x = self.conv4(x)\n",
        "      x = self.conv5(x)\n",
        "      x = self.avgpool(x)\n",
        "      x = torch.flatten(x, 1)\n",
        "      x = self.fc(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "EFVh1fNGRXyj"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def resnet18(self):\n",
        "        return Resnet(Basicblock, [2, 2, 2, 2])\n",
        "\n",
        "    def resnet34(self):\n",
        "        return Resnet(Basicblock, [3, 4, 6, 3])\n",
        "\n",
        "    def resnet50(self):\n",
        "        return Resnet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "    def resnet101(self):\n",
        "        return Resnet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    def resnet152(self):\n",
        "        return Resnet(Bottleneck, [3, 8, 36, 3])"
      ],
      "metadata": {
        "id": "XeZdYGIJ0lGO"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().resnet50().to(device)\n",
        "summary(model, input_size=(3, 224, 224), device=device.type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVzbJVIw1t7N",
        "outputId": "28e959bb-46b3-48b6-a719-b378111c6f44"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 28, 28]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
            "             ReLU-39          [-1, 128, 28, 28]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 14, 14]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
            "             ReLU-81          [-1, 256, 14, 14]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141            [-1, 512, 7, 7]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-143            [-1, 512, 7, 7]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                   [-1, 10]          20,490\n",
            "================================================================\n",
            "Total params: 23,528,522\n",
            "Trainable params: 23,528,522\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 274.49\n",
            "Params size (MB): 89.75\n",
            "Estimated Total Size (MB): 364.82\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋"
      ],
      "metadata": {
        "id": "Ml9X31edbJKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "xAlpbnhjFYNu"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/CIFAR10'\n",
        "if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "transfor = transforms.Compose([transforms.ToTensor()])\n",
        "trainset = datasets.CIFAR10(root=path, train=True, download=True, transform=transfor)\n",
        "testset = datasets.CIFAR10(root=path, train=False, download=True, transform=transfor)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2vac3vfFZHm",
        "outputId": "d55d1435-a07f-4e3f-f1fd-129bb1185ca1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(trainloader))"
      ],
      "metadata": {
        "id": "qlxNyMb0rVsE"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7KSW-Ey9zbH",
        "outputId": "226a1c5e-8935-409e-acfa-15df615abf46"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5725, 0.5412, 0.6039,  ..., 0.5373, 0.5176, 0.4863],\n",
              "         [0.4863, 0.4510, 0.4667,  ..., 0.3922, 0.3569, 0.4784],\n",
              "         [0.4980, 0.4784, 0.4667,  ..., 0.3882, 0.3686, 0.4706],\n",
              "         ...,\n",
              "         [0.7961, 0.7490, 0.4510,  ..., 0.6118, 0.6078, 0.6667],\n",
              "         [0.7686, 0.7725, 0.6863,  ..., 0.6510, 0.6353, 0.6314],\n",
              "         [0.7451, 0.7765, 0.7686,  ..., 0.7255, 0.7020, 0.6745]],\n",
              "\n",
              "        [[0.5451, 0.5098, 0.5451,  ..., 0.4941, 0.4745, 0.4353],\n",
              "         [0.4667, 0.4353, 0.4353,  ..., 0.3882, 0.3529, 0.4549],\n",
              "         [0.4588, 0.4275, 0.4196,  ..., 0.4039, 0.3804, 0.4549],\n",
              "         ...,\n",
              "         [0.7294, 0.7020, 0.4235,  ..., 0.5804, 0.5843, 0.6392],\n",
              "         [0.6902, 0.7059, 0.6431,  ..., 0.6196, 0.6118, 0.6039],\n",
              "         [0.6706, 0.6980, 0.7137,  ..., 0.6667, 0.6471, 0.6275]],\n",
              "\n",
              "        [[0.4588, 0.4353, 0.4784,  ..., 0.4157, 0.4039, 0.3961],\n",
              "         [0.4039, 0.3765, 0.3725,  ..., 0.3176, 0.3020, 0.4157],\n",
              "         [0.4039, 0.3725, 0.3608,  ..., 0.3451, 0.3333, 0.3922],\n",
              "         ...,\n",
              "         [0.6275, 0.6000, 0.3765,  ..., 0.4510, 0.4510, 0.5020],\n",
              "         [0.5843, 0.5961, 0.5608,  ..., 0.4863, 0.4784, 0.4706],\n",
              "         [0.5608, 0.5843, 0.5882,  ..., 0.5451, 0.5216, 0.5020]]])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDHatL5A_FzT",
        "outputId": "de7313a8-fa02-4d41-8ab3-c0fe72a76cd8"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 이미지 선택\n",
        "first_image = images[0]  # (3, 32, 32)\n",
        "\n",
        "# 채널 순서를 (높이, 너비, 채널)로 변경\n",
        "first_image = first_image.permute(1, 2, 0)  # (32, 32, 3)\n",
        "\n",
        "# 이미지 시각화\n",
        "plt.imshow(first_image)\n",
        "plt.axis('off')  # 축 숨기기\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "jCid2K_4-jLg",
        "outputId": "762807f6-0bd5-44c3-cd70-871569c36c70"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8EEh9Oa_r7d",
        "outputId": "976e5ac3-7040-4101-ced1-1877dca54397"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 평균 및 표준편차 계산\n",
        "mean = torch.zeros(3)\n",
        "std = torch.zeros(3)\n",
        "for images, _ in trainloader:\n",
        "    images = images.view(images.size(0), images.size(1), -1)\n",
        "    mean += images.mean(2).sum(0)\n",
        "    std += images.std(2).sum(0)\n",
        "\n",
        "mean /= len(trainset)\n",
        "std /= len(trainset)\n",
        "\n",
        "mean = mean.numpy().tolist()\n",
        "std = std.numpy().tolist()\n",
        "\n",
        "mean,std"
      ],
      "metadata": {
        "id": "-Hh_EIgCrUX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49aa3b4a-5413-4465-f5cc-bc8fe868c605"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.491399884223938, 0.48215845227241516, 0.4465309679508209],\n",
              " [0.2023009955883026, 0.19941280782222748, 0.20096160471439362])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# 저장할 파일 경로\n",
        "file_path = '/content/drive/MyDrive/resnet/mean_std.json'\n",
        "\n",
        "# 딕셔너리 형태로 데이터 준비\n",
        "data = {\n",
        "    'mean': mean,\n",
        "    'std': std\n",
        "}\n",
        "\n",
        "# JSON 파일로 저장\n",
        "with open(file_path, 'w') as f:\n",
        "    json.dump(data, f, indent=4)"
      ],
      "metadata": {
        "id": "qw8WoD_QCn8j"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 경로\n",
        "file_path = '/content/drive/MyDrive/resnet/mean_std.json'\n",
        "\n",
        "# JSON 파일에서 데이터 불러오기\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "mean = data['mean']\n",
        "std = data['std']\n",
        "mean,std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3l1X8EFC2uU",
        "outputId": "aef538c7-cfeb-4829-ae5f-0165532285d1"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.491399884223938, 0.48215845227241516, 0.4465309679508209],\n",
              " [0.2023009955883026, 0.19941280782222748, 0.20096160471439362])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 전처리\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 크기 변경\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),  # 계산된 평균과 표준편차를 이용한 정규화\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 크기 변경\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),  # 계산된 평균과 표준편차를 이용한 정규화\n",
        "])\n",
        "\n",
        "\n",
        "# CIFAR-10\n",
        "trainset = datasets.CIFAR10(root=path, train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root=path, train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "jLBvoGOIFl1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0abfd87-5cd7-464a-9230-de9f67bb60b6"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더 정보를 출력하는 함수\n",
        "def print_dataloader_info(dataloader, loader_name):\n",
        "    print(f\"{loader_name} 정보:\")\n",
        "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "        print(f\"배치 인덱스: {batch_idx}\")\n",
        "        print(f\"이미지 크기: {images.size()}\")\n",
        "        if isinstance(labels, torch.Tensor):\n",
        "            print(f\"라벨 크기: {labels.size()}\")\n",
        "            print(f'라벨의 데이터타입 : {labels[0].dtype}')\n",
        "        else:\n",
        "            print(f\"라벨 크기: {len(labels)}\")\n",
        "            print(f'라벨의 데이터타입 : {type(labels[0])}')\n",
        "        if batch_idx == 0:  # 첫 번째 배치 정보만 출력\n",
        "            break\n",
        "\n",
        "# train_loader 정보 출력\n",
        "print_dataloader_info(trainloader, \"Train Loader\")\n",
        "print(\"\\n\")\n",
        "# test_loader 정보 출력\n",
        "print_dataloader_info(testloader, \"Test Loader\")"
      ],
      "metadata": {
        "id": "TOU9EYmTFn0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085f92ee-a479-4cdf-cc70-8c0e30b2a8d0"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader 정보:\n",
            "배치 인덱스: 0\n",
            "이미지 크기: torch.Size([4, 3, 224, 224])\n",
            "라벨 크기: torch.Size([4])\n",
            "라벨의 데이터타입 : torch.int64\n",
            "\n",
            "\n",
            "Test Loader 정보:\n",
            "배치 인덱스: 0\n",
            "이미지 크기: torch.Size([4, 3, 224, 224])\n",
            "라벨 크기: torch.Size([4])\n",
            "라벨의 데이터타입 : torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련\n"
      ],
      "metadata": {
        "id": "Hc6Of7IXEHIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameters\n",
        "initial_learning_rate = 0.1\n",
        "num_epochs = 10\n",
        "epoch_step = 2\n",
        "\n",
        "# Loss function, optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=initial_learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "# scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True)"
      ],
      "metadata": {
        "id": "X-Y8F_dtEQtR"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(model, data_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    global epoch_step\n",
        "    running_size, running_loss, correct = 0.0, 0.0, 0.0\n",
        "\n",
        "    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n",
        "        pbar = tqdm(data_loader)\n",
        "    else:\n",
        "        pbar = data_loader\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_size += images.size(0)\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n",
        "            pbar.set_description('[Training] loss: ' +\n",
        "                                f'{running_loss / running_size:.4f}, accuracy: ' +\n",
        "                                f'{correct / running_size:.4f}')\n",
        "        del images, labels, outputs, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    avg_accuracy = correct / running_size\n",
        "    avg_loss = running_loss / running_size\n",
        "\n",
        "    return avg_loss, avg_accuracy\n",
        "\n",
        "def model_eval(model, data_loader, criterion, epoch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss, correct = 0.0, 0.0\n",
        "\n",
        "        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n",
        "            pbar = tqdm(data_loader)\n",
        "        else:\n",
        "            pbar = data_loader\n",
        "\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            pred = outputs.argmax(dim=1)\n",
        "\n",
        "            correct += torch.sum(pred == labels).item()\n",
        "            running_loss += criterion(outputs, labels).item() * images.size(0)\n",
        "\n",
        "        accuracy = correct / len(data_loader.dataset)\n",
        "        loss = running_loss / len(data_loader.dataset)\n",
        "        return loss, accuracy"
      ],
      "metadata": {
        "id": "OZnUAuffEIqT"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 및 평가 코드\n",
        "loss, accuracy = [], []\n",
        "num_epochs = 10\n",
        "epoch_step = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = model_train(model, trainloader, criterion, optimizer, epoch)\n",
        "    test_loss, test_accuracy = model_eval(model, testloader, criterion, epoch)\n",
        "\n",
        "    loss.append([train_loss, test_loss])\n",
        "    accuracy.append([train_accuracy, test_accuracy])\n",
        "\n",
        "    scheduler.step(test_loss)  # 스케줄러 업데이트\n",
        "\n",
        "    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n",
        "        print(f\"epoch {epoch+1:03d}, Training loss: \" +\n",
        "              f\"{train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
        "        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# 모델 상태 저장\n",
        "model_save_path = '/content/drive/MyDrive/resnet/model.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "bc3gWpyOGLHC",
        "outputId": "efb71747-0c43-4399-c81b-ca18ef17a119"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training] loss: 2.3168, accuracy: 0.1425:  48%|████▊     | 6002/12500 [4:07:00<4:27:25,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-22702e42db06>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-a71e75e10ab2>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(model, data_loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그래프 확인"
      ],
      "metadata": {
        "id": "xUYeMm7ZEKiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 손실 그래프\n",
        "train_losses, val_losses = zip(*loss)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(val_losses, label='val')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Train-Val Loss')\n",
        "\n",
        "# 정확도 그래프\n",
        "train_accuracies, val_accuracies = zip(*accuracy)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='train')\n",
        "plt.plot(val_accuracies, label='val')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Train-Val Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DjpBRw0dELwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 실행\n"
      ],
      "metadata": {
        "id": "gH23-ekfH98w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/resnet/model.pth'\n",
        "model = Model().resnet50().to(device)\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "I0FKoaAKH_GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(testloader))\n",
        "images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7PB9LwfMh-g",
        "outputId": "24942d77-c3a5-431a-e9ba-0e3e35e5e992"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6337,  0.6337,  0.6337,  ..., -0.1804, -0.1804, -0.1804],\n",
              "         [ 0.6337,  0.6337,  0.6337,  ..., -0.1804, -0.1804, -0.1804],\n",
              "         [ 0.6337,  0.6337,  0.6337,  ..., -0.1804, -0.1804, -0.1804],\n",
              "         ...,\n",
              "         [-1.3823, -1.3823, -1.3823,  ..., -2.0220, -2.0220, -2.0220],\n",
              "         [-1.3823, -1.3823, -1.3823,  ..., -2.0220, -2.0220, -2.0220],\n",
              "         [-1.3823, -1.3823, -1.3823,  ..., -2.0220, -2.0220, -2.0220]],\n",
              "\n",
              "        [[-0.2153, -0.2153, -0.2153,  ..., -0.7463, -0.7463, -0.7463],\n",
              "         [-0.2153, -0.2153, -0.2153,  ..., -0.7463, -0.7463, -0.7463],\n",
              "         [-0.2153, -0.2153, -0.2153,  ..., -0.7463, -0.7463, -0.7463],\n",
              "         ...,\n",
              "         [-0.3137, -0.3137, -0.3137,  ..., -1.1003, -1.1003, -1.1003],\n",
              "         [-0.3137, -0.3137, -0.3137,  ..., -1.1003, -1.1003, -1.1003],\n",
              "         [-0.3137, -0.3137, -0.3137,  ..., -1.1003, -1.1003, -1.1003]],\n",
              "\n",
              "        [[-1.2658, -1.2658, -1.2658,  ..., -1.5780, -1.5780, -1.5780],\n",
              "         [-1.2658, -1.2658, -1.2658,  ..., -1.5780, -1.5780, -1.5780],\n",
              "         [-1.2658, -1.2658, -1.2658,  ..., -1.5780, -1.5780, -1.5780],\n",
              "         ...,\n",
              "         [ 0.9003,  0.9003,  0.9003,  ..., -0.0754, -0.0754, -0.0754],\n",
              "         [ 0.9003,  0.9003,  0.9003,  ..., -0.0754, -0.0754, -0.0754],\n",
              "         [ 0.9003,  0.9003,  0.9003,  ..., -0.0754, -0.0754, -0.0754]]])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDIwY_Bk9OtF",
        "outputId": "0808f6be-7d32-4b15-d61e-c61121a0f942"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 텐서를 넘파이 배열로 변환\n",
        "label_indices = labels.numpy()\n",
        "\n",
        "# 각 레이블 인덱스를 클래스 이름으로 변환\n",
        "label_names = [class_labels[idx] for idx in label_indices]\n",
        "\n",
        "print(label_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WOWrHSo9z46",
        "outputId": "624c0683-a0f2-4bca-b88c-15b66faed74a"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cat', 'ship', 'ship', 'airplane']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 시각화\n",
        "plt.imshow(first_image)\n",
        "plt.axis('off')  # 축 숨기기\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "QmirSF5L9MFZ",
        "outputId": "e3fd5992-ed79-4c52-b7f9-5940d930ca90"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = trainset.classes\n",
        "class_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNeZWY4yOlfa",
        "outputId": "27731ee0-7f11-4823-b9c6-ae12ff05886b"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = images[0].unsqueeze(0)\n",
        "test_image.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjfFTXqdM0dH",
        "outputId": "1196345b-e783-45cb-ef81-816c06f459bb"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 모델에 통과시켜 예측 수행\n",
        "with torch.no_grad():  # 평가 시에는 gradient를 계산할 필요가 없음\n",
        "    outputs = model(test_image)\n",
        "value, label_idx = torch.max(outputs, 1)\n",
        "value, label_idx"
      ],
      "metadata": {
        "id": "fIMP1_iBILdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측된 클래스의 인덱스\n",
        "predicted_index = label_idx.item()  # 텐서에서 값을 꺼내 정수로 변환\n",
        "\n",
        "# 인덱스를 클래스 이름으로 매핑\n",
        "predicted_label = class_labels[predicted_index]\n",
        "predicted_label"
      ],
      "metadata": {
        "id": "_LZuC3HMOtrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qQjEmhTEbLbi",
        "Ml9X31edbJKH",
        "Hc6Of7IXEHIH",
        "xUYeMm7ZEKiY",
        "gH23-ekfH98w"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}